{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ABDULLAH-AHMAD-OFFICIAL/edge-connect-face-reconstruction/blob/main/colab/EdgeConnect_Face_Reconstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üé≠ EdgeConnect Face Reconstruction\n",
    "\n",
    "**Author:** ABDULLAH AHMAD  \n",
    "**Repository:** [edge-connect-face-reconstruction](https://github.com/ABDULLAH-AHMAD-OFFICIAL/edge-connect-face-reconstruction)\n",
    "\n",
    "Welcome to the EdgeConnect Face Reconstruction project! This notebook allows you to run advanced face inpainting directly in Google Colab with zero local setup required.\n",
    "\n",
    "## üåü What this does:\n",
    "- **Detects white mask regions** in facial images automatically\n",
    "- **Reconstructs missing areas** using edge-guided inpainting\n",
    "- **Provides high-quality results** using multiple inpainting algorithms\n",
    "- **Works with any image** containing white masks (like nose masks)\n",
    "\n",
    "## üöÄ Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üì¶ Step 1: Setup and Installation\n",
    "\n",
    "First, let's install all required dependencies and clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install",
    "outputId": "example-output"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision opencv-python pillow matplotlib scikit-image numpy scipy pyyaml\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/ABDULLAH-AHMAD-OFFICIAL/edge-connect-face-reconstruction.git\n",
    "%cd edge-connect-face-reconstruction\n",
    "\n",
    "# Install the package\n",
    "!pip install -e .\n",
    "\n",
    "print(\"‚úÖ Setup complete! Ready to reconstruct faces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## üìö Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# Import our custom modules\n",
    "from src.face_reconstructor import FaceReconstructor\n",
    "from src.utils import load_image, save_image\n",
    "\n",
    "# Configure matplotlib for better display\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['image.interpolation'] = 'bilinear'\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo"
   },
   "source": [
    "## üé® Step 3: Quick Demo with Sample Image\n",
    "\n",
    "Let's start with a quick demo using a sample image to see how the reconstruction works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_demo"
   },
   "outputs": [],
   "source": [
    "# Initialize the face reconstructor\n",
    "reconstructor = FaceReconstructor()\n",
    "\n",
    "# Create a sample image with white nose mask\n",
    "print(\"üé≠ Creating sample face with white nose mask...\")\n",
    "sample_path = reconstructor.create_sample_image(size=256, output_path='sample_face.jpg')\n",
    "\n",
    "# Display the sample image\n",
    "sample_img = load_image(sample_path)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(sample_img)\n",
    "plt.title('Sample Face with White Nose Mask', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample image created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "process_demo"
   },
   "outputs": [],
   "source": [
    "# Process the sample image\n",
    "print(\"üîÑ Processing sample image...\")\n",
    "results = reconstructor.process_image(sample_path, output_dir='./demo_output')\n",
    "\n",
    "# Visualize the results\n",
    "reconstructor.visualize_results(results, figsize=(18, 12))\n",
    "\n",
    "print(\"‚úÖ Demo completed! See the reconstruction results above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## üì§ Step 4: Upload Your Own Image\n",
    "\n",
    "Now let's process your own image! Upload an image with white mask regions that you want to reconstruct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_image"
   },
   "outputs": [],
   "source": [
    "# Upload your image\n",
    "print(\"üì§ Please upload your image with white mask regions:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded file\n",
    "uploaded_filename = list(uploaded.keys())[0]\n",
    "print(f\"‚úÖ Uploaded: {uploaded_filename}\")\n",
    "\n",
    "# Display the uploaded image\n",
    "uploaded_img = load_image(uploaded_filename)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(uploaded_img)\n",
    "plt.title(f'Your Uploaded Image: {uploaded_filename}', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image size: {uploaded_img.shape[1]}x{uploaded_img.shape[0]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "configure"
   },
   "source": [
    "## ‚öôÔ∏è Step 5: Configure Parameters (Optional)\n",
    "\n",
    "Adjust these parameters if needed for better results with your specific image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_params"
   },
   "outputs": [],
   "source": [
    "# Configuration parameters - adjust as needed\n",
    "config = {\n",
    "    'threshold': 240,        # White mask detection threshold (0-255)\n",
    "    'edge_sigma': 2,         # Edge detection blur strength\n",
    "    'edge_weight': 0.3,      # Edge guidance weight (0-1)\n",
    "    'inpaint_radius': 3,     # Inpainting radius\n",
    "    'target_size': (512, 512),  # Target processing size (optional)\n",
    "    'save_intermediate': True,\n",
    "    'output_quality': 95\n",
    "}\n",
    "\n",
    "# Update reconstructor with new config\n",
    "reconstructor.update_config(**config)\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration updated:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüí° Tips for parameter adjustment:\")\n",
    "print(\"  ‚Ä¢ Lower threshold (200-220) for lighter masks\")\n",
    "print(\"  ‚Ä¢ Higher edge_weight (0.4-0.6) for more edge emphasis\")\n",
    "print(\"  ‚Ä¢ Larger target_size for higher quality results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "process"
   },
   "source": [
    "## üéØ Step 6: Process Your Image\n",
    "\n",
    "Let's reconstruct your image using the configured parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "process_user"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"üîÑ Processing your image: {uploaded_filename}\")\n",
    "    print(\"This may take a few moments...\")\n",
    "    \n",
    "    # Process the uploaded image\n",
    "    results = reconstructor.process_image(\n",
    "        uploaded_filename, \n",
    "        output_dir='./your_results',\n",
    "        target_size=config.get('target_size')\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Processing completed!\")\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìä Reconstruction Results:\")\n",
    "    reconstructor.visualize_results(results, figsize=(20, 14))\n",
    "    \n",
    "    # Print statistics\n",
    "    mask_pixels = np.sum(results['mask'] > 0)\n",
    "    total_pixels = results['mask'].size\n",
    "    mask_percentage = (mask_pixels / total_pixels) * 100\n",
    "    \n",
    "    print(f\"\\nüìà Statistics:\")\n",
    "    print(f\"  ‚Ä¢ Mask pixels detected: {mask_pixels:,}\")\n",
    "    print(f\"  ‚Ä¢ Mask coverage: {mask_percentage:.2f}% of image\")\n",
    "    print(f\"  ‚Ä¢ Image dimensions: {results['original'].shape[1]}x{results['original'].shape[0]}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüí° Try adjusting the threshold parameter:\")\n",
    "    print(\"  ‚Ä¢ Lower threshold (200-220) for lighter masks\")\n",
    "    print(\"  ‚Ä¢ Check if your image actually contains white regions\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\")\n",
    "    print(\"Please check your image format and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## üíæ Step 7: Download Results\n",
    "\n",
    "Download all the generated results including the reconstructed image, mask, and comparison images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_results"
   },
   "outputs": [],
   "source": [
    "# Create a zip file with all results\n",
    "def create_results_zip():\n",
    "    zip_buffer = io.BytesIO()\n",
    "    \n",
    "    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "        # Add demo results\n",
    "        demo_dir = './demo_output'\n",
    "        if os.path.exists(demo_dir):\n",
    "            for file in os.listdir(demo_dir):\n",
    "                file_path = os.path.join(demo_dir, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    zip_file.write(file_path, f'demo/{file}')\n",
    "        \n",
    "        # Add user results\n",
    "        user_dir = './your_results'\n",
    "        if os.path.exists(user_dir):\n",
    "            for file in os.listdir(user_dir):\n",
    "                file_path = os.path.join(user_dir, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    zip_file.write(file_path, f'your_results/{file}')\n",
    "    \n",
    "    zip_buffer.seek(0)\n",
    "    return zip_buffer.getvalue()\n",
    "\n",
    "# Create and download the zip file\n",
    "print(\"üì¶ Creating download package...\")\n",
    "zip_data = create_results_zip()\n",
    "\n",
    "# Download the results\n",
    "files.download(io.BytesIO(zip_data), 'face_reconstruction_results.zip')\n",
    "print(\"‚úÖ Results downloaded as 'face_reconstruction_results.zip'\")\n",
    "\n",
    "print(\"\\nüìÅ Your download contains:\")\n",
    "print(\"  ‚Ä¢ demo/ - Sample reconstruction results\")\n",
    "print(\"  ‚Ä¢ your_results/ - Your image reconstruction results\")\n",
    "print(\"    ‚îú‚îÄ‚îÄ *_reconstructed.jpg - Final result\")\n",
    "print(\"    ‚îú‚îÄ‚îÄ *_mask.jpg - Detected mask\")\n",
    "print(\"    ‚îú‚îÄ‚îÄ *_edges.jpg - Edge detection\")\n",
    "    ‚îú‚îÄ‚îÄ *_comparison.jpg - Before vs after\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch"
   },
   "source": [
    "## üîÑ Step 8: Batch Processing (Optional)\n",
    "\n",
    "If you have multiple images to process, upload them all and process them in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch_upload"
   },
   "outputs": [],
   "source": [
    "# Upload multiple images for batch processing\n",
    "print(\"üì§ Upload multiple images for batch processing (optional):\")\n",
    "print(\"You can select multiple files at once!\")\n",
    "\n",
    "batch_uploaded = files.upload()\n",
    "\n",
    "if batch_uploaded:\n",
    "    print(f\"‚úÖ Uploaded {len(batch_uploaded)} images for batch processing\")\n",
    "    \n",
    "    # Create input directory\n",
    "    os.makedirs('./batch_input', exist_ok=True)\n",
    "    \n",
    "    # Move uploaded files to input directory\n",
    "    for filename in batch_uploaded.keys():\n",
    "        os.rename(filename, f'./batch_input/{filename}')\n",
    "    \n",
    "    # Process batch\n",
    "    print(\"üîÑ Processing batch...\")\n",
    "    reconstructor.batch_process('./batch_input', './batch_output')\n",
    "    \n",
    "    print(\"‚úÖ Batch processing completed!\")\n",
    "    \n",
    "    # Show summary\n",
    "    output_files = os.listdir('./batch_output')\n",
    "    print(f\"üìä Generated {len(output_files)} output files\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No files uploaded for batch processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "advanced"
   },
   "source": [
    "## üîß Step 9: Advanced Configuration & Tips\n",
    "\n",
    "Here are some advanced tips and parameter explanations for getting the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "advanced_tips"
   },
   "outputs": [],
   "source": [
    "print(\"üîß Advanced Configuration Tips:\")\nprint(\"\\nüéØ Threshold Parameter (threshold):\")\nprint(\"  ‚Ä¢ 240-255: Very selective, only pure white\")\nprint(\"  ‚Ä¢ 220-240: Good for most white masks\")\nprint(\"  ‚Ä¢ 200-220: More inclusive, catches light gray\")\nprint(\"  ‚Ä¢ 180-200: Very inclusive, may catch shadows\")\n\nprint(\"\\nüîç Edge Detection (edge_sigma):\")\nprint(\"  ‚Ä¢ 1-2: Sharp edges, good for clear images\")\nprint(\"  ‚Ä¢ 2-3: Balanced, works for most images\")\nprint(\"  ‚Ä¢ 3-5: Smoother edges, good for noisy images\")\n\nprint(\"\\n‚öñÔ∏è Edge Weight (edge_weight):\")\nprint(\"  ‚Ä¢ 0.1-0.3: Subtle edge guidance\")\nprint(\"  ‚Ä¢ 0.3-0.5: Balanced approach (recommended)\")\nprint(\"  ‚Ä¢ 0.5-0.8: Strong edge emphasis\")\n\nprint(\"\\nüìè Image Size (target_size):\")\nprint(\"  ‚Ä¢ (256, 256): Fast processing, lower quality\")\nprint(\"  ‚Ä¢ (512, 512): Balanced speed/quality\")\nprint(\"  ‚Ä¢ (1024, 1024): High quality, slower processing\")\nprint(\"  ‚Ä¢ None: Use original size\")\n\nprint(\"\\nüí° Troubleshooting:\")\nprint(\"  ‚Ä¢ 'No white regions detected': Lower threshold\")\nprint(\"  ‚Ä¢ Poor edge detection: Adjust edge_sigma\")\nprint(\"  ‚Ä¢ Blurry results: Increase target_size\")\nprint(\"  ‚Ä¢ Artifacts in result: Try different edge_weight\")\n\n# Example of parameter testing\nprint(\"\\nüß™ Want to test different parameters?\")\nprint(\"Modify the config dictionary in Step 5 and re-run Step 6!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "about"
   },
   "source": [
    "## ‚ÑπÔ∏è About This Project\n",
    "\n",
    "### üéØ What is EdgeConnect Face Reconstruction?\n",
    "\n",
    "This project implements an EdgeConnect-inspired approach for reconstructing masked facial regions. It's particularly effective for:\n",
    "\n",
    "- **Medical masks and face coverings**\n",
    "- **Privacy protection applications**\n",
    "- **Photo restoration**\n",
    "- **Digital art and creative projects**\n",
    "\n",
    "### üî¨ How it works:\n",
    "\n",
    "1. **Mask Detection**: Automatically identifies white/light regions\n",
    "2. **Edge Analysis**: Uses Canny edge detection to understand structure\n",
    "3. **Edge Propagation**: Extends edges into masked regions\n",
    "4. **Inpainting**: Combines multiple algorithms for natural results\n",
    "5. **Blending**: Merges results using edge guidance\n",
    "\n",
    "### üë®‚Äçüíª Author\n",
    "\n",
    "**ABDULLAH AHMAD**  \n",
    "GitHub: [@ABDULLAH-AHMAD-OFFICIAL](https://github.com/ABDULLAH-AHMAD-OFFICIAL)  \n",
    "Repository: [edge-connect-face-reconstruction](https://github.com/ABDULLAH-AHMAD-OFFICIAL/edge-connect-face-reconstruction)\n",
    "\n",
    "### üìÑ License\n",
    "\n",
    "This project is licensed under the MIT License - see the [LICENSE](https://github.com/ABDULLAH-AHMAD-OFFICIAL/edge-connect-face-reconstruction/blob/main/LICENSE) file for details.\n",
    "\n",
    "### üôè Acknowledgments\n",
    "\n",
    "- Original EdgeConnect paper: [Nazeri et al., 2019](https://arxiv.org/abs/1901.00212)\n",
    "- OpenCV community for inpainting algorithms\n",
    "\n",
    "---\n",
    "\n",
    "‚≠ê **If you found this helpful, please star the repository!** ‚≠ê\n",
    "\n",
    "üêõ **Found a bug or have suggestions?** [Open an issue](https://github.com/ABDULLAH-AHMAD-OFFICIAL/edge-connect-face-reconstruction/issues)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM...",
   "collapsed_sections": [],
   "name": "EdgeConnect_Face_Reconstruction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}