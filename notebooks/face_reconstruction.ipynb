{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Reconstruction with EdgeConnect\n",
    "\n",
    "This notebook demonstrates how to use EdgeConnect for face reconstruction, specifically for inpainting masked regions (like the white nose mask in the provided image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from skimage import feature\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add the src directory to Python path\n",
    "sys.path.append('./src')\n",
    "\n",
    "# Import EdgeConnect modules\n",
    "from edge_connect import EdgeConnect\n",
    "from utils import create_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare the Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration for face reconstruction\n",
    "config = {\n",
    "    'MODE': 1,  # 1: train, 2: test, 3: eval\n",
    "    'MODEL': 3,  # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n",
    "    'MASK': 3,  # 1: random block, 2: half, 3: external, 4: external + random block, 5: external + random block + half\n",
    "    'EDGE': 1,  # 1: canny, 2: external\n",
    "    'NMS': 1,   # 0: no non-max-suppression, 1: non-max-suppression on the external edges\n",
    "    'SEED': 10,\n",
    "    'GPU': [0],\n",
    "    'DEBUG': 0,\n",
    "    'VERBOSE': 1,\n",
    "    \n",
    "    # Training configurations\n",
    "    'LR': 0.0001,\n",
    "    'D2G_LR': 0.1,\n",
    "    'BETA1': 0.0,\n",
    "    'BETA2': 0.9,\n",
    "    'BATCH_SIZE': 8,\n",
    "    'INPUT_SIZE': 256,\n",
    "    'SIGMA': 2,\n",
    "    'MAX_ITERS': 2000000,\n",
    "    'EDGE_THRESHOLD': 0.5,\n",
    "    'L1_LOSS_WEIGHT': 1,\n",
    "    'FM_LOSS_WEIGHT': 10,\n",
    "    'STYLE_LOSS_WEIGHT': 1,\n",
    "    'CONTENT_LOSS_WEIGHT': 1,\n",
    "    'INPAINT_ADV_LOSS_WEIGHT': 0.01,\n",
    "    'GAN_LOSS': 'nsgan',\n",
    "    'GAN_POOL_SIZE': 0,\n",
    "    'SAVE_INTERVAL': 1000,\n",
    "    'EVAL_INTERVAL': 0,\n",
    "    'LOG_INTERVAL': 10,\n",
    "    'SAMPLE_INTERVAL': 1000,\n",
    "    'SAMPLE_SIZE': 12,\n",
    "    \n",
    "    # Paths (will be set dynamically)\n",
    "    'PATH': './checkpoints',\n",
    "    'TRAIN_FLIST': '',\n",
    "    'VAL_FLIST': '',\n",
    "    'TEST_FLIST': '',\n",
    "    'TRAIN_EDGE_FLIST': '',\n",
    "    'VAL_EDGE_FLIST': '',\n",
    "    'TEST_EDGE_FLIST': '',\n",
    "    'TRAIN_MASK_FLIST': '',\n",
    "    'VAL_MASK_FLIST': '',\n",
    "    'TEST_MASK_FLIST': ''\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, size=None):\n",
    "    \"\"\"Load and preprocess image\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    if size:\n",
    "        image = image.resize(size, Image.LANCZOS)\n",
    "    return np.array(image)\n",
    "\n",
    "def create_mask_from_white_regions(image, threshold=240):\n",
    "    \"\"\"Create mask from white regions in the image (like the nose mask)\"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Create mask where white regions are\n",
    "    mask = (gray > threshold).astype(np.uint8) * 255\n",
    "    \n",
    "    # Apply morphological operations to clean up the mask\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def to_tensor(image):\n",
    "    \"\"\"Convert numpy array to tensor\"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        image = image.transpose(2, 0, 1)\n",
    "    return torch.from_numpy(image.astype(np.float32) / 255.0).unsqueeze(0)\n",
    "\n",
    "def from_tensor(tensor):\n",
    "    \"\"\"Convert tensor to numpy array\"\"\"\n",
    "    if tensor.dim() == 4:\n",
    "        tensor = tensor.squeeze(0)\n",
    "    image = tensor.cpu().detach().numpy()\n",
    "    if len(image.shape) == 3:\n",
    "        image = image.transpose(1, 2, 0)\n",
    "    return (image * 255).astype(np.uint8)\n",
    "\n",
    "def canny_edge_detection(image, sigma=2, low_threshold=0.1, high_threshold=0.2):\n",
    "    \"\"\"Apply Canny edge detection\"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (0, 0), sigma)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blurred, int(low_threshold * 255), int(high_threshold * 255))\n",
    "    \n",
    "    return edges\n",
    "\n",
    "print(\"Utility functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple EdgeConnect Implementation\n",
    "\n",
    "Since we may not have pre-trained models, let's create a simple version that uses traditional inpainting techniques with edge guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEdgeConnect:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        \n",
    "    def edge_guided_inpainting(self, image, mask):\n",
    "        \"\"\"Perform edge-guided inpainting using traditional methods\"\"\"\n",
    "        # Step 1: Extract edges from the non-masked regions\n",
    "        edges = canny_edge_detection(image, sigma=self.config['SIGMA'])\n",
    "        \n",
    "        # Step 2: Mask the edges (remove edges in masked regions)\n",
    "        edges_masked = edges.copy()\n",
    "        edges_masked[mask > 0] = 0\n",
    "        \n",
    "        # Step 3: Extend edges into masked regions using morphological operations\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        edges_dilated = cv2.dilate(edges_masked, kernel, iterations=2)\n",
    "        \n",
    "        # Step 4: Create edge guidance for inpainting\n",
    "        edge_guidance = edges_dilated.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Step 5: Convert mask for OpenCV inpainting (255 for regions to inpaint)\n",
    "        inpaint_mask = mask.copy()\n",
    "        \n",
    "        # Step 6: Perform inpainting using Telea method\n",
    "        inpainted = cv2.inpaint(image, inpaint_mask, 3, cv2.INPAINT_TELEA)\n",
    "        \n",
    "        # Step 7: Enhance inpainting using Fast Marching method\n",
    "        inpainted_fm = cv2.inpaint(image, inpaint_mask, 3, cv2.INPAINT_NS)\n",
    "        \n",
    "        # Step 8: Blend results based on edge guidance\n",
    "        edge_weight = 0.3\n",
    "        final_result = (1 - edge_weight) * inpainted + edge_weight * inpainted_fm\n",
    "        \n",
    "        return final_result.astype(np.uint8), edges, edges_dilated\n",
    "    \n",
    "    def process_image(self, image_path, output_path=None):\n",
    "        \"\"\"Process a single image\"\"\"\n",
    "        # Load image\n",
    "        image = load_image(image_path, size=(self.config['INPUT_SIZE'], self.config['INPUT_SIZE']))\n",
    "        \n",
    "        # Create mask from white regions\n",
    "        mask = create_mask_from_white_regions(image)\n",
    "        \n",
    "        # Perform edge-guided inpainting\n",
    "        result, edges, edges_dilated = self.edge_guided_inpainting(image, mask)\n",
    "        \n",
    "        # Visualize results\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        \n",
    "        axes[0, 0].imshow(image)\n",
    "        axes[0, 0].set_title('Original Image with Mask')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        axes[0, 1].imshow(mask, cmap='gray')\n",
    "        axes[0, 1].set_title('Detected Mask')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        axes[0, 2].imshow(edges, cmap='gray')\n",
    "        axes[0, 2].set_title('Canny Edges')\n",
    "        axes[0, 2].axis('off')\n",
    "        \n",
    "        axes[1, 0].imshow(edges_dilated, cmap='gray')\n",
    "        axes[1, 0].set_title('Dilated Edges')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        axes[1, 1].imshow(result)\n",
    "        axes[1, 1].set_title('Inpainted Result')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        # Show comparison\n",
    "        comparison = np.hstack([image, result])\n",
    "        axes[1, 2].imshow(comparison)\n",
    "        axes[1, 2].set_title('Before vs After')\n",
    "        axes[1, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save result if output path is provided\n",
    "        if output_path:\n",
    "            Image.fromarray(result).save(output_path)\n",
    "            print(f\"Result saved to {output_path}\")\n",
    "        \n",
    "        return result, mask, edges\n",
    "\n",
    "print(\"SimpleEdgeConnect class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced EdgeConnect with Neural Networks\n",
    "\n",
    "Let's also implement a more advanced version that tries to use the actual EdgeConnect architecture if models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pretrained_models():\n",
    "    \"\"\"Check if pre-trained models are available\"\"\"\n",
    "    model_paths = {\n",
    "        'celeba': './checkpoints/celeba',\n",
    "        'places2': './checkpoints/places2',\n",
    "        'paris': './checkpoints/paris'\n",
    "    }\n",
    "    \n",
    "    available_models = []\n",
    "    for name, path in model_paths.items():\n",
    "        if os.path.exists(path):\n",
    "            available_models.append(name)\n",
    "    \n",
    "    return available_models\n",
    "\n",
    "def try_load_edge_connect():\n",
    "    \"\"\"Try to load the actual EdgeConnect model\"\"\"\n",
    "    try:\n",
    "        # Check for available models\n",
    "        available_models = check_pretrained_models()\n",
    "        print(f\"Available pre-trained models: {available_models}\")\n",
    "        \n",
    "        if available_models:\n",
    "            # Try to initialize EdgeConnect with the first available model\n",
    "            model_path = f\"./checkpoints/{available_models[0]}\"\n",
    "            \n",
    "            # Create config file for the model\n",
    "            config_path = os.path.join(model_path, 'config.yml')\n",
    "            if not os.path.exists(config_path):\n",
    "                # Create a basic config\n",
    "                with open(config_path, 'w') as f:\n",
    "                    yaml.dump(config, f)\n",
    "            \n",
    "            # Try to load the model\n",
    "            model = EdgeConnect(config)\n",
    "            model.load()\n",
    "            return model, True\n",
    "        else:\n",
    "            print(\"No pre-trained models found. Using simple implementation.\")\n",
    "            return None, False\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading EdgeConnect: {e}\")\n",
    "        print(\"Falling back to simple implementation.\")\n",
    "        return None, False\n",
    "\n",
    "# Try to load the actual EdgeConnect model\n",
    "edge_connect_model, model_loaded = try_load_edge_connect()\n",
    "\n",
    "if model_loaded:\n",
    "    print(\"EdgeConnect model loaded successfully!\")\n",
    "else:\n",
    "    print(\"Using simple EdgeConnect implementation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Sample Input Image\n",
    "\n",
    "Let's create a sample image with a white mask for testing if you don't have the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_face_with_mask():\n",
    "    \"\"\"Create a sample face image with a white nose mask for testing\"\"\"\n",
    "    # Create a simple face-like image\n",
    "    size = 256\n",
    "    image = np.ones((size, size, 3), dtype=np.uint8) * 200  # Light background\n",
    "    \n",
    "    # Add some facial features\n",
    "    center_x, center_y = size // 2, size // 2\n",
    "    \n",
    "    # Face outline (ellipse)\n",
    "    cv2.ellipse(image, (center_x, center_y), (80, 100), 0, 0, 360, (180, 150, 120), -1)\n",
    "    \n",
    "    # Eyes\n",
    "    cv2.circle(image, (center_x - 25, center_y - 20), 8, (50, 50, 50), -1)\n",
    "    cv2.circle(image, (center_x + 25, center_y - 20), 8, (50, 50, 50), -1)\n",
    "    \n",
    "    # Mouth\n",
    "    cv2.ellipse(image, (center_x, center_y + 30), (15, 8), 0, 0, 180, (100, 50, 50), 2)\n",
    "    \n",
    "    # Add white nose mask\n",
    "    nose_points = np.array([\n",
    "        [center_x - 10, center_y - 5],\n",
    "        [center_x + 10, center_y - 5],\n",
    "        [center_x + 8, center_y + 15],\n",
    "        [center_x - 8, center_y + 15]\n",
    "    ], np.int32)\n",
    "    \n",
    "    cv2.fillPoly(image, [nose_points], (255, 255, 255))\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Create and save sample image\n",
    "sample_image = create_sample_face_with_mask()\n",
    "sample_path = './input_images/sample_face_with_mask.jpg'\n",
    "Image.fromarray(sample_image).save(sample_path)\n",
    "\n",
    "# Display the sample image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(sample_image)\n",
    "plt.title('Sample Face with White Nose Mask')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sample image created and saved to {sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Face Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simple EdgeConnect model\n",
    "simple_model = SimpleEdgeConnect(config)\n",
    "\n",
    "# Test with the sample image\n",
    "print(\"Testing face reconstruction with sample image...\")\n",
    "result, mask, edges = simple_model.process_image(\n",
    "    sample_path, \n",
    "    output_path='./output_reconstructed.jpg'\n",
    ")\n",
    "\n",
    "print(\"Face reconstruction completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Process Your Own Image\n",
    "\n",
    "To process your own image with a white mask, save it to the input_images folder and update the path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process your own image\n",
    "# Replace 'your_image.jpg' with the actual filename of your image\n",
    "your_image_path = './input_images/your_image.jpg'\n",
    "\n",
    "if os.path.exists(your_image_path):\n",
    "    print(\"Processing your image...\")\n",
    "    result, mask, edges = simple_model.process_image(\n",
    "        your_image_path, \n",
    "        output_path='./your_image_reconstructed.jpg'\n",
    "    )\n",
    "    print(\"Your image reconstruction completed!\")\n",
    "else:\n",
    "    print(f\"Image not found at {your_image_path}\")\n",
    "    print(\"Please save your image to the input_images folder and update the path above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Configuration and Tips\n",
    "\n",
    "Here are some tips for better results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_inpainting(image_path, mask_threshold=240, edge_sigma=2):\n",
    "    \"\"\"Advanced inpainting with customizable parameters\"\"\"\n",
    "    # Load image\n",
    "    image = load_image(image_path, size=(256, 256))\n",
    "    \n",
    "    # Create mask with custom threshold\n",
    "    mask = create_mask_from_white_regions(image, threshold=mask_threshold)\n",
    "    \n",
    "    # Apply different inpainting methods\n",
    "    methods = {\n",
    "        'Telea': cv2.INPAINT_TELEA,\n",
    "        'Fast Marching': cv2.INPAINT_NS\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, method in methods.items():\n",
    "        result = cv2.inpaint(image, mask, 3, method)\n",
    "        results[name] = result\n",
    "    \n",
    "    # Display comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    axes[0, 0].imshow(image)\n",
    "    axes[0, 0].set_title('Original with Mask')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(mask, cmap='gray')\n",
    "    axes[0, 1].set_title('Detected Mask')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(results['Telea'])\n",
    "    axes[1, 0].set_title('Telea Method')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(results['Fast Marching'])\n",
    "    axes[1, 1].set_title('Fast Marching Method')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test advanced inpainting with different parameters\n",
    "print(\"Testing advanced inpainting methods...\")\n",
    "advanced_results = advanced_inpainting(sample_path)\n",
    "print(\"Advanced inpainting completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Basic EdgeConnect Implementation**: A simplified version using traditional inpainting with edge guidance\n",
    "2. **Mask Detection**: Automatic detection of white regions to create inpainting masks\n",
    "3. **Edge-Guided Inpainting**: Using Canny edge detection to guide the inpainting process\n",
    "4. **Multiple Inpainting Methods**: Comparison of different OpenCV inpainting algorithms\n",
    "\n",
    "### For Better Results:\n",
    "\n",
    "1. **Download Pre-trained Models**: Use the official EdgeConnect pre-trained models for state-of-the-art results\n",
    "2. **Fine-tune Parameters**: Adjust edge detection and inpainting parameters based on your specific images\n",
    "3. **Use GPU**: Enable GPU acceleration for faster processing with the full EdgeConnect model\n",
    "4. **Custom Training**: Train the model on your specific dataset for domain-specific improvements\n",
    "\n",
    "### Usage:\n",
    "\n",
    "1. Save your image with white mask to `./input_images/`\n",
    "2. Update the path in the \"Process Your Own Image\" section\n",
    "3. Run the cells to see the reconstruction results\n",
    "\n",
    "The results will show the original image, detected mask, edge information, and the final reconstructed image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}